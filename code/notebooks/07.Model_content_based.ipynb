{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:44:44.304757Z",
     "start_time": "2025-06-07T12:44:44.298275Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "714ba904b04a2dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:44:50.123672Z",
     "start_time": "2025-06-07T12:44:47.108178Z"
    }
   },
   "source": [
    "# ========= LOAD DATA =========\n",
    "DATA_DIR = os.path.join('..', '..', 'data', 'cleaned')\n",
    "TARGET_DATA_DIR = os.path.join('..', '..', 'data', 'cleaned','joblib_dataframes')\n",
    "\n",
    "movies = joblib.load(os.path.join(TARGET_DATA_DIR, 'df_final.joblib'))\n",
    "\n",
    "meta_files = {\n",
    "    'actors':     'dim_movie_actors.csv',\n",
    "    'directors':  'dim_movie_directors.csv',\n",
    "    'producers':  'dim_movie_producers.csv',\n",
    "    'writers':    'dim_movie_writers.csv',\n",
    "    'categories': 'dim_movie_categories.csv',\n",
    "}\n",
    "\n",
    "meta_maps = {\n",
    "    'actors': pd.read_csv(os.path.join(DATA_DIR, 'dim_movie_actors.csv')).set_index('actor_name_id')['actor_name'].to_dict(),\n",
    "    'directors': pd.read_csv(os.path.join(DATA_DIR, 'dim_movie_directors.csv')).set_index('director_name_id')['director_name'].to_dict(),\n",
    "    'producers': pd.read_csv(os.path.join(DATA_DIR, 'dim_movie_producers.csv')).set_index('producer_name_id')['producer_name'].to_dict(),\n",
    "    'writers': pd.read_csv(os.path.join(DATA_DIR, 'dim_movie_writers.csv')).set_index('writer_name_id')['writer_name'].to_dict(),\n",
    "    'categories': pd.read_csv(os.path.join(DATA_DIR, 'dim_movie_categories.csv')).set_index('movie_category_id')['movie_category'].to_dict(),\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:45:05.367961Z",
     "start_time": "2025-06-07T12:45:05.359853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= DECODE HELPER FUNCTION =========\n",
    "def decode_ids(id_input, mapping_dict):\n",
    "    try:\n",
    "        # If it's a string, parse it\n",
    "        if isinstance(id_input, str):\n",
    "            id_list = ast.literal_eval(id_input)\n",
    "\n",
    "        # If it's type int or np.int, parse it\n",
    "        elif isinstance(id_input, (int, np.integer)):\n",
    "            id_list = id_input\n",
    "\n",
    "        # if it's already an array or list\n",
    "        elif isinstance(id_input, (list, np.ndarray)):\n",
    "            id_list = id_input\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "        # Zorg dat alles in id_list strings zijn\n",
    "        return '|'.join([mapping_dict.get(str(i), f'Unknown_{i}') for i in id_list])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding: {id_input} → {e}\")\n",
    "        return ''"
   ],
   "id": "cd95487d39fa3f27",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:45:10.051825Z",
     "start_time": "2025-06-07T12:45:09.881897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= FEAUTURE ENGINEERING =========\n",
    "for name, mapping in meta_maps.items():\n",
    "    movies[f'{name}_str'] = movies[name].apply(lambda x: decode_ids(x, mapping))\n",
    "\n",
    "existing_cols = [f'{k}_str' for k in meta_maps.keys() if f'{k}_str' in movies.columns]\n",
    "movies['combined_features'] = movies[existing_cols].fillna('').agg('|'.join, axis=1)"
   ],
   "id": "c6965d5db47e3a89",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:45:14.043694Z",
     "start_time": "2025-06-07T12:45:12.864113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= TF-IDF & COSINE SIMILARITY =========\n",
    "\"\"\"\n",
    "TF-IDF = Term Frequency – Inverse Document Frequency\n",
    "\n",
    "- TF (Term Frequency):\n",
    "  Measures how frequently a term appears in a document.\n",
    "  Example: If \"Will Smith\" appears in 2 movies, its TF is high.\n",
    "\n",
    "- IDF (Inverse Document Frequency):\n",
    "  Measures how rare a term is across all documents.\n",
    "  Example: If \"Will Smith\" appears in many movies, its IDF is low.\n",
    "           If \"Michael Bay\" appears in only one movie, its IDF is high.\n",
    "\n",
    "Why TF-IDF?\n",
    "-----------\n",
    "TF-IDF helps highlight important and unique words in text data while downweighting common, less informative terms.\n",
    "\n",
    "Cosine Similarity\n",
    "-----------------\n",
    "- Treats every movie as a vector (based on TF-IDF features).\n",
    "- Measures the angle between two vectors (movies).\n",
    "- Range: 0   → no similarity\n",
    "         1   → exactly the same\n",
    "\"\"\"\n",
    "\n",
    "tfidf = TfidfVectorizer(token_pattern=r'[^|]+')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['combined_features'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "title_to_index = pd.Series(movies.index, index=movies['title'])"
   ],
   "id": "418a9e218fd65c52",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:45:16.821124Z",
     "start_time": "2025-06-07T12:45:16.800006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= RECOMMENDER FUNCTION =========\n",
    "def content_recommendations(title, top_n=5):\n",
    "    if title not in title_to_index:\n",
    "        return [\"Title not found.\"]\n",
    "    idx = title_to_index[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, _ in sim_scores[1:top_n+1]]\n",
    "    return movies['title'].iloc[top_indices].tolist()\n",
    "\n",
    "# Example usage\n",
    "print(content_recommendations(\"Bad Boys II\", top_n=5))"
   ],
   "id": "df6c05233a4e4bf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hollywood Homicide', 'National Treasure: Book of Secrets', 'National Treasure', 'Pearl Harbor', \"My Mom's New Boyfriend\"]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T12:45:46.241514Z",
     "start_time": "2025-06-07T12:45:21.820145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= CREATE OUTPUT FOR OTHER MODELING IN OTHER NOTEBOOKS =========\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "df_tfidf.index = movies.index\n",
    "df_movies_combined_rf = pd.concat([movies, df_tfidf], axis=1)\n",
    "\n",
    "joblib.dump(df_movies_combined_rf, os.path.join(TARGET_DATA_DIR, \"df_movies_combined_rf.joblib\"))"
   ],
   "id": "78fe80152a9b85b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/cleaned/joblib_dataframes/df_movies_combined_rf.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
