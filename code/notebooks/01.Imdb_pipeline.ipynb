{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b6835492be88b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:18:20.280420Z",
     "start_time": "2025-05-25T09:18:18.865834Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e12d5272673e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:18:20.376686Z",
     "start_time": "2025-05-25T09:18:20.304226Z"
    }
   },
   "outputs": [],
   "source": [
    "# ========= CONFIG ========= \n",
    "\n",
    "BASE_URL = \"https://datasets.imdbws.com/\"\n",
    "DATASET_FILES = [\n",
    "    \"name.basics.tsv.gz\",\n",
    "    \"title.basics.tsv.gz\",\n",
    "    \"title.principals.tsv.gz\",\n",
    "    \"title.ratings.tsv.gz\"\n",
    "]\n",
    "SOURCE_SYSTEM = 'imdb'\n",
    "RAW_DATA_DIR = os.path.join('..', '..', 'data', 'raw', 'imdb')\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "TSV_SEPARATOR = '\\t'\n",
    "TSV_DECIMAL_SIGN = '.'\n",
    "TSV_NA_VALUES = r'\\N'\n",
    "CHUNKSIZE = 10**5 # For reading large TSV files in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb829c1eef74f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:18:20.669Z",
     "start_time": "2025-05-25T09:18:20.658077Z"
    }
   },
   "outputs": [],
   "source": [
    "# ========= HELP FUNCTION  ========= \n",
    "\n",
    "def download_file(url, destination_path):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        with open(destination_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192): # Increased chunk size for efficiency\n",
    "                file.write(chunk)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return False\n",
    "\n",
    "def unzip_gz_file(gz_path, output_path):\n",
    "    try:\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(output_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def rename_imdb_tsv(file_path, source_system):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if not file_name.endswith('.tsv'):\n",
    "        return None # Only process .tsv files\n",
    "\n",
    "    parts = file_name.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        new_file_name = f\"{source_system}_{parts[0]}_{parts[1]}.tsv\"\n",
    "        new_path = os.path.join(os.path.dirname(file_path), new_file_name)\n",
    "        try:\n",
    "            os.rename(file_path, new_path)\n",
    "            return new_path\n",
    "        except OSError as e:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def read_filtered_tsv_in_chunks(filepath, filter_col, filter_values,\n",
    "                                 selected_cols=None, new_col_names=None):\n",
    "    df_collected = pd.DataFrame()\n",
    "    for chunk in pd.read_csv(filepath, sep=TSV_SEPARATOR, decimal=TSV_DECIMAL_SIGN,\n",
    "                             dtype=str, na_values=TSV_NA_VALUES, chunksize=CHUNKSIZE):\n",
    "        filtered_chunk = chunk[chunk[filter_col].isin(filter_values)]\n",
    "        df_collected = pd.concat([df_collected, filtered_chunk], ignore_index=True)\n",
    "\n",
    "    if selected_cols and new_col_names:\n",
    "        columns_dict = dict(zip(selected_cols, new_col_names))\n",
    "        df_collected = df_collected[selected_cols].rename(columns=columns_dict)\n",
    "\n",
    "    return df_collected.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4dee0796358095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:22:38.988340Z",
     "start_time": "2025-05-25T09:18:20.754318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished Data Download and Preparation ---\n"
     ]
    }
   ],
   "source": [
    "# ========= DOWNLOAD & PREPARE RAW DATA ========= \n",
    "\n",
    "# --- Download, Unzip, and Rename Files ---\n",
    "for dataset in DATASET_FILES:\n",
    "    file_url = BASE_URL + dataset\n",
    "    gz_destination_path = os.path.join(RAW_DATA_DIR, dataset)\n",
    "    tsv_output_path = os.path.join(RAW_DATA_DIR, os.path.splitext(dataset)[0]) # path before renaming\n",
    "\n",
    "    if download_file(file_url, gz_destination_path):\n",
    "        if unzip_gz_file(gz_destination_path, tsv_output_path):\n",
    "            os.remove(gz_destination_path) # Clean up .gz file after unzipping\n",
    "            rename_imdb_tsv(tsv_output_path, SOURCE_SYSTEM)\n",
    "\n",
    "print(\"--- Finished Data Download and Preparation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d8b266fbe74866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:23:32.720751Z",
     "start_time": "2025-05-25T09:22:39.091556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished Preparing Movie ID List ---\n"
     ]
    }
   ],
   "source": [
    "# ========= PREPARE MOVIE ID LIST ========= \n",
    "\n",
    "file_title_basics_renamed = os.path.join(RAW_DATA_DIR, f'{SOURCE_SYSTEM}_title_basics.tsv')\n",
    "\n",
    "# Load and filter title basics to get the relevant movie IDs\n",
    "df_basics_raw = pd.read_csv(\n",
    "    file_title_basics_renamed,\n",
    "    sep=TSV_SEPARATOR,\n",
    "    decimal=TSV_DECIMAL_SIGN,\n",
    "    dtype=str,\n",
    "    na_values=TSV_NA_VALUES\n",
    ")\n",
    "\n",
    "df_filtered_movies = df_basics_raw[\n",
    "    (df_basics_raw['titleType'] == 'movie') &\n",
    "    (df_basics_raw['isAdult'] == '0') &\n",
    "    (~df_basics_raw['genres'].isna())\n",
    "].copy()\n",
    "\n",
    "# Convert numerical columns and handle errors\n",
    "df_filtered_movies['startYear'] = pd.to_numeric(df_filtered_movies['startYear'], errors='coerce').fillna(0).astype(int)\n",
    "df_filtered_movies['runtimeMinutes'] = pd.to_numeric(df_filtered_movies['runtimeMinutes'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Apply additional filtering criteria\n",
    "current_year = datetime.now().year\n",
    "df_filtered_movies = df_filtered_movies[\n",
    "    (df_filtered_movies['startYear'] >= 2000) &\n",
    "    (df_filtered_movies['runtimeMinutes'] >= 90) &\n",
    "    (df_filtered_movies['startYear'] < current_year)\n",
    "].copy()\n",
    "\n",
    "# Extract IMDb IDs\n",
    "df_imdb_movie_ids = df_filtered_movies[['tconst']].rename(columns={'tconst': 'imdb_movie_id'})\n",
    "df_imdb_movie_ids = df_imdb_movie_ids.sort_values(by='imdb_movie_id').reset_index(drop=True)\n",
    "\n",
    "# Save the list of relevant IMDb movie IDs\n",
    "imdb_ids_path = os.path.join(RAW_DATA_DIR, f'{SOURCE_SYSTEM}_movie_ids.csv')\n",
    "df_imdb_movie_ids.to_csv(imdb_ids_path, index=False)\n",
    "imdb_ids = df_imdb_movie_ids['imdb_movie_id'].tolist() # Convert to list for efficient 'isin' checks\n",
    "\n",
    "print(\"--- Finished Preparing Movie ID List ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1303b27fd365a9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:32:15.866805Z",
     "start_time": "2025-05-25T09:23:32.771009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- All Dataset Transformations Complete ---\n"
     ]
    }
   ],
   "source": [
    "# =========  TRANSFORM DATASET FILES ========= \n",
    "\n",
    "# --- Transform title.basics.tsv ---\n",
    "selected_cols_basics = ['tconst', 'originalTitle', 'startYear', 'runtimeMinutes', 'genres']\n",
    "new_col_names_basics = ['movie_imdb_id', 'movie_title', 'movie_release_year', 'movie_duration_minutes', 'movie_categories']\n",
    "df_movie_titles = read_filtered_tsv_in_chunks(\n",
    "    file_title_basics_renamed,\n",
    "    filter_col='tconst',\n",
    "    filter_values=imdb_ids,\n",
    "    selected_cols=selected_cols_basics,\n",
    "    new_col_names=new_col_names_basics\n",
    ")\n",
    "df_movie_titles.to_csv(os.path.join(RAW_DATA_DIR, f\"{SOURCE_SYSTEM}_movie_titles.csv\"), index=False)\n",
    "\n",
    "# --- Transform title.ratings.tsv ---\n",
    "file_title_ratings_renamed = os.path.join(RAW_DATA_DIR, f'{SOURCE_SYSTEM}_title_ratings.tsv')\n",
    "selected_cols_ratings = ['tconst', 'averageRating', 'numVotes']\n",
    "new_col_names_ratings = ['movie_imdb_id', 'movie_imdb_rating', 'movie_imdb_nof_votes']\n",
    "df_title_ratings = read_filtered_tsv_in_chunks(\n",
    "    file_title_ratings_renamed,\n",
    "    filter_col='tconst',\n",
    "    filter_values=imdb_ids,\n",
    "    selected_cols=selected_cols_ratings,\n",
    "    new_col_names=new_col_names_ratings\n",
    ")\n",
    "df_title_ratings.to_csv(os.path.join(RAW_DATA_DIR, f\"{SOURCE_SYSTEM}_movie_ratings.csv\"), index=False)\n",
    "\n",
    "# --- Transform title.principals.tsv ---\n",
    "file_title_principals_renamed = os.path.join(RAW_DATA_DIR, f'{SOURCE_SYSTEM}_title_principals.tsv')\n",
    "title_principal_categories = ['director', 'actor', 'actress', 'writer', 'producer']\n",
    "\n",
    "df_t_principals_raw = pd.DataFrame()\n",
    "for chunk in pd.read_csv(file_title_principals_renamed, sep=TSV_SEPARATOR, decimal=TSV_DECIMAL_SIGN,\n",
    "                         dtype=str, na_values=TSV_NA_VALUES, chunksize=CHUNKSIZE):\n",
    "    # Filter by both tconst and category in one go\n",
    "    filtered_chunk = chunk[(chunk['tconst'].isin(imdb_ids)) & (chunk['category'].isin(title_principal_categories))]\n",
    "    df_t_principals_raw = pd.concat([df_t_principals_raw, filtered_chunk], ignore_index=True)\n",
    "\n",
    "selected_cols_principals = ['tconst', 'nconst', 'category']\n",
    "new_col_names_principals = ['movie_imdb_id', 'movie_person_name_id', 'movie_person_role']\n",
    "df_title_principals = df_t_principals_raw[selected_cols_principals].rename(columns=dict(zip(selected_cols_principals, new_col_names_principals))).reset_index(drop=True)\n",
    "\n",
    "# Normalize 'actress' role to 'actor'\n",
    "df_title_principals['movie_person_role'] = df_title_principals['movie_person_role'].replace({'actress': 'actor'})\n",
    "df_title_principals.to_csv(os.path.join(RAW_DATA_DIR, f\"{SOURCE_SYSTEM}_movie_principals.csv\"), index=False)\n",
    "\n",
    "# Create a list of unique movie person name IDs for filtering name.basics.tsv\n",
    "movie_person_name_ids = df_title_principals['movie_person_name_id'].unique().tolist()\n",
    "\n",
    "# --- Transform name.basics.tsv (Movie Persons) ---\n",
    "file_name_basics_renamed = os.path.join(RAW_DATA_DIR, f'{SOURCE_SYSTEM}_name_basics.tsv')\n",
    "selected_cols_persons = ['nconst', 'primaryName', 'birthYear', 'deathYear']\n",
    "new_col_names_persons = ['movie_person_name_id', 'movie_person_name', 'movie_person_birth_year', 'movie_person_death_year']\n",
    "\n",
    "df_movie_persons = read_filtered_tsv_in_chunks(\n",
    "    file_name_basics_renamed,\n",
    "    filter_col='nconst',\n",
    "    filter_values=movie_person_name_ids,\n",
    "    selected_cols=selected_cols_persons,\n",
    "    new_col_names=new_col_names_persons\n",
    ")\n",
    "df_movie_persons = df_movie_persons.sort_values('movie_person_name_id').reset_index(drop=True)\n",
    "df_movie_persons.to_csv(os.path.join(RAW_DATA_DIR, f\"{SOURCE_SYSTEM}_movie_persons.csv\"), index=False)\n",
    "\n",
    "print(\"--- All Dataset Transformations Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
